{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_images_and_labels(directories, exclude_dir=None):\n",
    "    labels = []\n",
    "    images = []\n",
    "    for directory in directories:\n",
    "        for dir_name, _, file_list in os.walk(directory):\n",
    "            if dir_name == exclude_dir:  # skip the excluded directory\n",
    "                continue\n",
    "            for filename in file_list:\n",
    "                if filename.endswith('.png'):\n",
    "                    # the label is the first word of the filename\n",
    "                    label = filename.split(' ')[0]  # update the separator depending on your file naming convention\n",
    "                    labels.append(label)\n",
    "\n",
    "                    # load and preprocess the image\n",
    "                    img_path = os.path.join(dir_name, filename)\n",
    "                    img = load_img(img_path, target_size=(32, 32))  # the target size depends on your requirements\n",
    "                    img_array = img_to_array(img) / 255.0  # convert to array and normalize to range [0, 1]\n",
    "                    images.append(img_array)\n",
    "    \n",
    "    print(f\"Number of images: {len(images)}, Number of labels: {len(labels)}\")  # Debug line\n",
    "\n",
    "    if not images:\n",
    "        print(f\"No images found in directories: {directories}\")\n",
    "\n",
    "    # Convert labels to one-hot encoding\n",
    "    le = LabelEncoder()\n",
    "    if labels:\n",
    "        labels = le.fit_transform(labels)\n",
    "        labels = tf.keras.utils.to_categorical(labels)\n",
    "    else:\n",
    "        print(\"No labels found. Returning...\")\n",
    "        return [], []\n",
    "\n",
    "    return images, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 200, Number of labels: 200\n",
      "Number of images: 50, Number of labels: 50\n"
     ]
    }
   ],
   "source": [
    "train_dirs = [\"./data/Fold1\",\n",
    "              \"./data/Fold2\",\n",
    "              \"./data/Fold3\",\n",
    "              \"./data/Fold4\"]\n",
    "test_dir = \"./data/Fold5\"\n",
    "\n",
    "train_images, train_labels = load_images_and_labels(train_dirs, exclude_dir=test_dir)\n",
    "test_images, test_labels = load_images_and_labels([test_dir])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, AveragePooling2D, Flatten, Dense\n",
    "\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    # Layer 1: Convolutional + Average pooling\n",
    "    model.add(Conv2D(filters=6, kernel_size=(5, 5), activation='tanh', input_shape=(32, 32, 3)))\n",
    "    model.add(AveragePooling2D())\n",
    "\n",
    "    # Layer 2: Convolutional + Average pooling\n",
    "    model.add(Conv2D(filters=16, kernel_size=(5, 5), activation='tanh'))\n",
    "    model.add(AveragePooling2D())\n",
    "\n",
    "    # Flatten the image to one dimensional array\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # Layer 3: Fully connected layer (Dense)\n",
    "    model.add(Dense(units=120, activation='tanh'))\n",
    "\n",
    "    # Layer 4: Fully connected layer (Dense)\n",
    "    model.add(Dense(units=84, activation='tanh'))\n",
    "\n",
    "    # Layer 5: Output layer\n",
    "    model.add(Dense(units=5, activation = 'softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_accuracy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Specify training parameters: batch size and number of epochs\n",
    "batch_size = 32\n",
    "epochs = 20\n",
    "\n",
    "def train_model(train_images, train_labels, verbose):\n",
    "    # Building model\n",
    "    model= build_model()\n",
    "    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Importing data\n",
    "\n",
    "    # Convert images and labels to numpy arrays\n",
    "    train_images = np.array(train_images)\n",
    "    train_labels = np.array(train_labels)\n",
    "\n",
    "    # Train the model using the training data\n",
    "    history = model.fit(train_images, train_labels, batch_size=batch_size, epochs=epochs, validation_split=0.2, verbose=verbose)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_images, test_labels):\n",
    "    # Convert test images and labels to numpy arrays\n",
    "    test_images = np.array(test_images)\n",
    "    test_labels = np.array(test_labels)\n",
    "\n",
    "    # Evaluate the model on the test data\n",
    "    loss, accuracy = model.evaluate(test_images, test_labels)\n",
    "\n",
    "    print(f\"Test set accuracy: {accuracy * 100:.2f}%\")\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 200, Number of labels: 200\n",
      "Number of images: 50, Number of labels: 50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1345 - accuracy: 0.9800\n",
      "Test set accuracy: 98.00%\n"
     ]
    }
   ],
   "source": [
    "train_dirs = [\"./data/Fold1\", \"./data/Fold2\", \"./data/Fold3\", \"./data/Fold4\"]\n",
    "test_dir = \"./data/Fold5\"\n",
    "\n",
    "train_images, train_labels = load_images_and_labels(train_dirs, exclude_dir=test_dir)\n",
    "test_images, test_labels = load_images_and_labels([test_dir])\n",
    "\n",
    "model = train_model(train_images, train_labels, verbose=0)\n",
    "\n",
    "accuracy = test_model(model, test_images, test_labels)\n",
    "models_accuracy.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 200, Number of labels: 200\n",
      "Number of images: 50, Number of labels: 50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0868 - accuracy: 1.0000\n",
      "Test set accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "train_dirs = [\"./data/Fold5\", \"./data/Fold1\", \"./data/Fold2\", \"./data/Fold3\"]\n",
    "test_dir = \"./data/Fold4\"\n",
    "\n",
    "train_images, train_labels = load_images_and_labels(train_dirs, exclude_dir=test_dir)\n",
    "test_images, test_labels = load_images_and_labels([test_dir])\n",
    "\n",
    "model = train_model(train_images, train_labels, verbose=0)\n",
    "\n",
    "accuracy = test_model(model, test_images, test_labels)\n",
    "models_accuracy.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 200, Number of labels: 200\n",
      "Number of images: 50, Number of labels: 50\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1395 - accuracy: 0.9600\n",
      "Test set accuracy: 96.00%\n"
     ]
    }
   ],
   "source": [
    "train_dirs = [\"./data/Fold4\", \"./data/Fold5\", \"./data/Fold1\", \"./data/Fold2\"]\n",
    "test_dir = \"./data/Fold3\"\n",
    "\n",
    "train_images, train_labels = load_images_and_labels(train_dirs, exclude_dir=test_dir)\n",
    "test_images, test_labels = load_images_and_labels([test_dir])\n",
    "\n",
    "model = train_model(train_images, train_labels, verbose=0)\n",
    "\n",
    "accuracy = test_model(model, test_images, test_labels)\n",
    "models_accuracy.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 200, Number of labels: 200\n",
      "Number of images: 50, Number of labels: 50\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0927 - accuracy: 0.9400\n",
      "Test set accuracy: 94.00%\n"
     ]
    }
   ],
   "source": [
    "train_dirs = [\"./data/Fold3\", \"./data/Fold4\", \"./data/Fold5\", \"./data/Fold1\"]\n",
    "test_dir = \"./data/Fold2\"\n",
    "\n",
    "train_images, train_labels = load_images_and_labels(train_dirs, exclude_dir=test_dir)\n",
    "test_images, test_labels = load_images_and_labels([test_dir])\n",
    "\n",
    "model = train_model(train_images, train_labels, verbose=0)\n",
    "\n",
    "accuracy = test_model(model, test_images, test_labels)\n",
    "models_accuracy.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 200, Number of labels: 200\n",
      "Number of images: 50, Number of labels: 50\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2374 - accuracy: 0.8800\n",
      "Test set accuracy: 88.00%\n"
     ]
    }
   ],
   "source": [
    "train_dirs = [\"./data/Fold2\", \"./data/Fold3\", \"./data/Fold4\", \"./data/Fold5\"]\n",
    "test_dir = \"./data/Fold1\"\n",
    "\n",
    "train_images, train_labels = load_images_and_labels(train_dirs, exclude_dir=test_dir)\n",
    "test_images, test_labels = load_images_and_labels([test_dir])\n",
    "\n",
    "model = train_model(train_images, train_labels, verbose=0)\n",
    "\n",
    "accuracy = test_model(model, test_images, test_labels)\n",
    "models_accuracy.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia média: 95.20%\n",
      "Desvio Padrão: 4.12%\n"
     ]
    }
   ],
   "source": [
    "mean_accuracy = np.average(models_accuracy)\n",
    "std_accuracy = np.std(models_accuracy)\n",
    "print(f\"Acurácia média: {mean_accuracy * 100:.2f}%\")\n",
    "print(f\"Desvio Padrão: {std_accuracy* 100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sis-int",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
